{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sz = 5000\n",
    "csv = \"synth_nonlinear.csv\"\n",
    "df = pd.read_csv(csv)\n",
    "df_test = df.iloc[-1000:]\n",
    "df = df.iloc[:dataset_sz]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "n_folds = 10\n",
    "df = scaler.fit_transform(df)\n",
    "df_test = scaler.transform(df_test)\n",
    "\n",
    "X_test = df_test\n",
    "y_test = df_test[:,0]\n",
    "X_DAG = df\n",
    "y_DAG = np.expand_dims(X_DAG[:,0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "num_train = X_DAG.shape[0]\n",
    "lr  = None\n",
    "batch_size = 32\n",
    "num_inputs = X_DAG.shape[1]\n",
    "num_outputs = 1\n",
    "w_threshold = 0.3\n",
    "n_hidden = 10\n",
    "# hidden_layers = 2\n",
    "ckpt_file = 'tmp.ckpt'\n",
    "# standardize = True\n",
    "reg_lambda=1\n",
    "reg_beta=5\n",
    "# DAG_min = 0.5\n",
    "learning_rate = 0.001\n",
    "\n",
    "max_steps = 200\n",
    "saves = 50 \n",
    "patience = 30\n",
    "# metric = mean_squared_error\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(None, 10) dtype=float32, numpy=\n",
       " array([[-1.484536  , -1.5275788 ,  0.48957345, ..., -0.9901357 ,\n",
       "         -0.68122566,  0.09370673],\n",
       "        [ 2.0711331 , -0.77660966,  0.5837853 , ...,  1.7845517 ,\n",
       "          0.45600224, -0.7173038 ],\n",
       "        [-0.36621284, -0.68882316,  0.8255042 , ...,  0.97385097,\n",
       "          1.1061857 , -1.1758687 ],\n",
       "        ...,\n",
       "        [-0.70872915, -1.0960492 ,  0.5624519 , ..., -1.8072734 ,\n",
       "          0.40068227, -1.2580615 ],\n",
       "        [-0.81493574, -0.45984966, -0.15990469, ..., -0.45329618,\n",
       "         -0.30793667, -0.6496865 ],\n",
       "        [ 1.2409345 ,  0.7310152 , -0.8439071 , ...,  1.3917621 ,\n",
       "          0.09549129,  0.75522476]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(None, 1) dtype=float32, numpy=\n",
       " array([[-1.484536  ],\n",
       "        [ 2.0711331 ],\n",
       "        [-0.36621284],\n",
       "        ...,\n",
       "        [-0.70872915],\n",
       "        [-0.81493574],\n",
       "        [ 1.2409345 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create input tensors\n",
    "X = tf.Variable(initial_value = X_DAG, shape=[None, num_inputs], dtype=tf.dtypes.float32)\n",
    "y = tf.Variable(initial_value = y_DAG, dtype=tf.dtypes.float32, shape=[None, 1])\n",
    "X, y\n",
    "\n",
    "# rho =  tf.placeholder(\"float\",[1,1])\n",
    "# alpha =  tf.placeholder(\"float\",[1,1])\n",
    "# keep_prob = tf.placeholder(\"float\")\n",
    "# Lambda = tf.placeholder(\"float\")\n",
    "# noise = tf.placeholder(\"float\")\n",
    "# is_train = tf.placeholder(tf.bool, name=\"is_train\")\n",
    "\n",
    "# One-hot vector indicating which nodes are trained\n",
    "# sample = tf.Variable(dtype=tf.int32, shape=[num_inputs])\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {}\n",
    "biases = {}\n",
    "\n",
    "# Create the input and output weight matrix for each feature\n",
    "for i in range(num_inputs):\n",
    "    weights['w_h0_'+str(i)] = tf.Variable(tf.random.normal([num_inputs, n_hidden], seed = seed))\n",
    "    weights['out_'+str(i)] = tf.Variable(tf.random.normal([n_hidden, num_outputs], seed = seed))\n",
    "\n",
    "for i in range(num_inputs):\n",
    "    biases['b_h0_'+str(i)] = tf.Variable(tf.random.normal([n_hidden], seed = seed))\n",
    "    biases['out_'+str(i)] = tf.Variable(tf.random.normal([num_outputs], seed = seed))\n",
    "\n",
    "# The first layer is shared\n",
    "weights.update({\n",
    "    'w_h1': tf.Variable(tf.random.normal([n_hidden, n_hidden]))\n",
    "})\n",
    "\n",
    "biases.update({\n",
    "    'b_h1': tf.Variable(tf.random.normal([n_hidden]))\n",
    "})\n",
    "\n",
    "# weights\n",
    "# biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create two hidden layer network with masking\n",
    "## one output per input.. reconstructing the inputs\n",
    "\n",
    "hidden_h0 = {}\n",
    "hidden_h1 = {}\n",
    "layer_1 = {}\n",
    "layer_1_dropout = {}\n",
    "out_layer = {}\n",
    "\n",
    "Out_0 = []\n",
    "\n",
    "# Mask removes the feature i from the network that is tasked to construct feature i\n",
    "mask = {}\n",
    "activation = tf.nn.relu\n",
    "\n",
    "for i in range(num_inputs):\n",
    "    indices = [i]*n_hidden\n",
    "    mask[str(i)] = tf.transpose(tf.one_hot(indices, depth=num_inputs, on_value=0.0, off_value=1.0, axis=-1))\n",
    "\n",
    "    weights['w_h0_'+str(i)] = weights['w_h0_'+str(i)]*mask[str(i)] \n",
    "    hidden_h0['nn_'+str(i)] = activation(tf.add(tf.matmul(X, weights['w_h0_'+str(i)]), biases['b_h0_'+str(i)]))\n",
    "    hidden_h1['nn_'+str(i)] = activation(tf.add(tf.matmul(hidden_h0['nn_'+str(i)], weights['w_h1']), biases['b_h1']))\n",
    "    out_layer['nn_'+str(i)] = tf.matmul(hidden_h1['nn_'+str(i)], weights['out_'+str(i)]) + biases['out_'+str(i)]\n",
    "    Out_0.append(out_layer['nn_'+str(i)])\n",
    "\n",
    "# Concatenate all the constructed features\n",
    "Out = tf.concat(Out_0,axis=1)\n",
    "\n",
    "# weights\n",
    "# hidden_h1\n",
    "# out_layer\n",
    "# Out_0\n",
    "# Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0.       , 2.9891484, 2.9120748, 2.607893 , 2.2550366, 3.9059763,\n",
       "        2.974898 , 2.0598476, 3.0118651, 3.3969736],\n",
       "       [3.258621 , 0.       , 2.1467886, 3.4455414, 3.7271032, 4.587194 ,\n",
       "        3.1495423, 3.4206116, 2.7484396, 3.1217365],\n",
       "       [3.8992577, 3.861907 , 0.       , 4.720157 , 3.374345 , 2.5452418,\n",
       "        2.3650439, 3.796946 , 2.6909115, 4.1147914],\n",
       "       [2.9020035, 1.8003858, 2.5942261, 0.       , 4.149866 , 3.6990008,\n",
       "        4.134482 , 3.070836 , 2.6891289, 3.1626332],\n",
       "       [2.7818089, 3.53201  , 2.3762486, 3.468664 , 0.       , 4.06795  ,\n",
       "        1.8370348, 3.1209235, 3.4086907, 1.71804  ],\n",
       "       [3.345568 , 2.8428469, 3.0271053, 2.1238883, 4.9395933, 0.       ,\n",
       "        2.1189463, 2.6840472, 3.9657218, 3.0005105],\n",
       "       [3.7834094, 3.3540597, 4.2328653, 3.0827007, 2.6465695, 3.3646953,\n",
       "        0.       , 2.60578  , 3.2701423, 4.304406 ],\n",
       "       [2.5742152, 2.8836102, 2.2753868, 3.1720796, 2.8149788, 4.0252476,\n",
       "        3.0171237, 0.       , 3.2793086, 2.1586692],\n",
       "       [3.142834 , 3.437799 , 2.5860586, 4.2328434, 2.2699175, 3.082491 ,\n",
       "        4.5992355, 3.110925 , 0.       , 3.2002635],\n",
       "       [4.714893 , 3.1082492, 2.7685952, 2.8610709, 3.165823 , 4.260805 ,\n",
       "        3.7223399, 2.2951727, 1.8446541, 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Adjeciency matrix\n",
    "## L2 norm of W\n",
    "W_0 = []\n",
    "for i in range(num_inputs):\n",
    "    W_0.append(tf.math.sqrt(tf.reduce_sum(tf.square(weights['w_h0_'+str(i)]),axis=1,keepdims=True)))\n",
    "\n",
    "W = tf.concat(W_0,axis=1)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1789651000000.0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## R_W\n",
    "\n",
    "d = tf.cast(X.shape[1], tf.float32)\n",
    "coff = 1.0 \n",
    "Z = tf.multiply(W,W)\n",
    "\n",
    "dag_l = tf.cast(d, tf.float32) \n",
    "\n",
    "Z_in = tf.eye(d)\n",
    "\n",
    "#truncated power series (truncated at 10)\n",
    "for i in range(1,10):\n",
    "\n",
    "    Z_in = tf.matmul(Z_in, Z)\n",
    "#     print(Z_in)\n",
    "#     print(tf.linalg.trace(Z_in))\n",
    "    \n",
    "    dag_l += 1./coff * tf.linalg.trace(Z_in)\n",
    "    \n",
    "#     print(coff, 1./coff)\n",
    "    \n",
    "    coff = coff * (i+1)\n",
    "    \n",
    "## R_W\n",
    "h = dag_l - tf.cast(d, tf.float32)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weigths tf.Tensor(\n",
      "[[-0.          0.          0.         -0.          0.          0.\n",
      "   0.         -0.         -0.         -0.        ]\n",
      " [ 0.6435448  -0.26432407  1.8566332   0.5678417  -0.3828359  -1.4853433\n",
      "   1.2617711  -0.02530608 -0.2646297   1.5328138 ]\n",
      " [-1.7429771  -0.43789294 -0.56601     0.32066926  1.132831   -2.2782571\n",
      "   0.48281202 -1.3127087   0.35685033 -1.7302834 ]\n",
      " [-0.04016773  0.8996619  -1.3805891   1.4814624  -0.2454948  -0.7326472\n",
      "  -0.19589645  0.07170801  0.6329809  -1.5711907 ]\n",
      " [ 1.3293812  -1.173367    0.0315446   0.47705248  0.43694198 -0.3168089\n",
      "  -0.45075032 -1.8060657   0.12489964 -0.7706542 ]\n",
      " [-0.74624157 -0.28195325 -1.9588155  -0.3376107   1.0301983   1.5134017\n",
      "   0.22515805 -0.28566208  0.26882544  1.746211  ]\n",
      " [ 0.92387104 -2.0590997  -0.31438306  1.2103382   0.694803   -1.06555\n",
      "   0.01364011 -1.0677125  -0.18407504 -2.2056234 ]\n",
      " [ 1.8290592   1.2431902  -0.33655512 -0.04000888 -0.33585522 -0.30744898\n",
      "  -0.7669297  -0.28710833 -0.29470286 -0.8099063 ]\n",
      " [-1.3159019   0.37532416  0.17755835 -2.0582864   0.40742677 -1.007233\n",
      "   0.29265752  0.5163359   1.4809465   0.10440207]\n",
      " [-2.416029   -0.6054818   0.04622507 -0.6681525  -0.4033087   0.7072242\n",
      "  -1.7900763   0.36240223 -2.7669072   1.9807922 ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor([], shape=(0, 10), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[ 0.6435448  -0.26432407  1.8566332   0.5678417  -0.3828359  -1.4853433\n",
      "   1.2617711  -0.02530608 -0.2646297   1.5328138 ]\n",
      " [-1.7429771  -0.43789294 -0.56601     0.32066926  1.132831   -2.2782571\n",
      "   0.48281202 -1.3127087   0.35685033 -1.7302834 ]\n",
      " [-0.04016773  0.8996619  -1.3805891   1.4814624  -0.2454948  -0.7326472\n",
      "  -0.19589645  0.07170801  0.6329809  -1.5711907 ]\n",
      " [ 1.3293812  -1.173367    0.0315446   0.47705248  0.43694198 -0.3168089\n",
      "  -0.45075032 -1.8060657   0.12489964 -0.7706542 ]\n",
      " [-0.74624157 -0.28195325 -1.9588155  -0.3376107   1.0301983   1.5134017\n",
      "   0.22515805 -0.28566208  0.26882544  1.746211  ]\n",
      " [ 0.92387104 -2.0590997  -0.31438306  1.2103382   0.694803   -1.06555\n",
      "   0.01364011 -1.0677125  -0.18407504 -2.2056234 ]\n",
      " [ 1.8290592   1.2431902  -0.33655512 -0.04000888 -0.33585522 -0.30744898\n",
      "  -0.7669297  -0.28710833 -0.29470286 -0.8099063 ]\n",
      " [-1.3159019   0.37532416  0.17755835 -2.0582864   0.40742677 -1.007233\n",
      "   0.29265752  0.5163359   1.4809465   0.10440207]\n",
      " [-2.416029   -0.6054818   0.04622507 -0.6681525  -0.4033087   0.7072242\n",
      "  -1.7900763   0.36240223 -2.7669072   1.9807922 ]], shape=(9, 10), dtype=float32) tf.Tensor(30.40261, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[-0.37988347  1.8781023   0.7018748  -1.4865124   0.04921798  0.35767043\n",
      "  -1.1620456  -0.48487446  0.61620426  0.6823264 ]\n",
      " [ 0.          0.          0.          0.         -0.         -0.\n",
      "   0.         -0.         -0.          0.        ]\n",
      " [-0.45578238  1.5286653  -0.98886555 -0.93964696 -1.1081889  -1.5194675\n",
      "  -0.6898558   2.3679407  -0.91611326 -0.22317104]\n",
      " [-0.06798524 -0.9083823  -0.09068037 -1.1554524   0.5949393  -0.2862282\n",
      "  -0.66259456  0.05944384  0.39320484 -0.18777977]\n",
      " [ 0.05993979 -1.3768727  -0.81024444  0.16975844  0.46360418  1.6294304\n",
      "   2.1689384  -0.61440295 -0.25559983  1.3686938 ]\n",
      " [-0.02722018  0.5682268   0.86811423  0.23225632 -0.10848879 -0.05046859\n",
      "   0.5595099  -1.286768    0.41551536  2.1897027 ]\n",
      " [ 0.6104519  -1.7096026   0.22985071  1.2646488   0.22148871  1.9262006\n",
      "   0.4659439  -0.7407295  -0.0092631   1.3330348 ]\n",
      " [-0.15514514 -1.5633552  -1.3715502  -0.52576673  0.6921284  -0.51813483\n",
      "  -0.807885    1.5071212  -0.04885908 -0.12448459]\n",
      " [ 0.12816031 -0.0681642   0.8390333  -0.8584028   1.2435641   1.0034487\n",
      "  -0.3025388   1.7137636  -1.8542366  -1.1560661 ]\n",
      " [ 0.9510954  -1.0995415  -1.0241009  -1.1470509  -1.4331976   0.582631\n",
      "  -1.1152443   0.45293006  0.7234252  -0.9040773 ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[-0.37988347  1.8781023   0.7018748  -1.4865124   0.04921798  0.35767043\n",
      "  -1.1620456  -0.48487446  0.61620426  0.6823264 ]], shape=(1, 10), dtype=float32) tf.Tensor(2.9891481, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[-0.45578238  1.5286653  -0.98886555 -0.93964696 -1.1081889  -1.5194675\n",
      "  -0.6898558   2.3679407  -0.91611326 -0.22317104]\n",
      " [-0.06798524 -0.9083823  -0.09068037 -1.1554524   0.5949393  -0.2862282\n",
      "  -0.66259456  0.05944384  0.39320484 -0.18777977]\n",
      " [ 0.05993979 -1.3768727  -0.81024444  0.16975844  0.46360418  1.6294304\n",
      "   2.1689384  -0.61440295 -0.25559983  1.3686938 ]\n",
      " [-0.02722018  0.5682268   0.86811423  0.23225632 -0.10848879 -0.05046859\n",
      "   0.5595099  -1.286768    0.41551536  2.1897027 ]\n",
      " [ 0.6104519  -1.7096026   0.22985071  1.2646488   0.22148871  1.9262006\n",
      "   0.4659439  -0.7407295  -0.0092631   1.3330348 ]\n",
      " [-0.15514514 -1.5633552  -1.3715502  -0.52576673  0.6921284  -0.51813483\n",
      "  -0.807885    1.5071212  -0.04885908 -0.12448459]\n",
      " [ 0.12816031 -0.0681642   0.8390333  -0.8584028   1.2435641   1.0034487\n",
      "  -0.3025388   1.7137636  -1.8542366  -1.1560661 ]\n",
      " [ 0.9510954  -1.0995415  -1.0241009  -1.1470509  -1.4331976   0.582631\n",
      "  -1.1152443   0.45293006  0.7234252  -0.9040773 ]], shape=(8, 10), dtype=float32) tf.Tensor(24.820868, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[ 0.3090834   1.070827    0.40732247  0.5346232   1.180236    0.7897521\n",
      "  -0.05628075 -1.49589    -0.7336282  -1.4108558 ]\n",
      " [-0.06285495  0.00737587 -0.6802899   1.2559718   0.41150764 -0.65336263\n",
      "   1.1978898  -0.00627629 -0.42059752 -0.59693754]\n",
      " [ 0.          0.          0.         -0.         -0.          0.\n",
      "   0.         -0.         -0.          0.        ]\n",
      " [ 1.3749427  -0.42972028 -0.51024634  0.10456268  0.63195425  1.6782017\n",
      "  -0.49928796 -0.37061718  0.2635748  -0.8436546 ]\n",
      " [-0.47306406 -0.11318148  1.8850484   0.2607874   0.5363164  -0.827118\n",
      "  -0.3614637  -0.5911786   0.5518568   0.17912847]\n",
      " [-0.5551494  -0.719139   -1.7393461   1.0084383  -0.8343097  -0.3490072\n",
      "  -1.1842831  -0.05278108  1.2000328   0.79528195]\n",
      " [-0.25930122  1.6491328  -0.576588    0.20397878 -1.3427229   0.7348453\n",
      "   0.93605685 -0.6909419  -1.0859869  -3.1433005 ]\n",
      " [-0.42067775  0.30126107  1.6660576   0.17846759 -0.58098996 -0.05399999\n",
      "  -0.8024532   0.08204538 -0.8270486  -0.6533913 ]\n",
      " [-0.6954217  -0.18104383  1.5689511   1.0846441   1.0638872   0.24641441\n",
      "   0.5751619   0.63819045  0.76238585  0.14609687]\n",
      " [ 0.9870894   1.0732305  -1.4681525  -0.81634253  0.33970132 -0.7715835\n",
      "  -0.13229224 -1.2610861  -0.14093159  0.6153246 ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[ 0.3090834   1.070827    0.40732247  0.5346232   1.180236    0.7897521\n",
      "  -0.05628075 -1.49589    -0.7336282  -1.4108558 ]\n",
      " [-0.06285495  0.00737587 -0.6802899   1.2559718   0.41150764 -0.65336263\n",
      "   1.1978898  -0.00627629 -0.42059752 -0.59693754]], shape=(2, 10), dtype=float32) tf.Tensor(5.0588636, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[ 1.3749427  -0.42972028 -0.51024634  0.10456268  0.63195425  1.6782017\n",
      "  -0.49928796 -0.37061718  0.2635748  -0.8436546 ]\n",
      " [-0.47306406 -0.11318148  1.8850484   0.2607874   0.5363164  -0.827118\n",
      "  -0.3614637  -0.5911786   0.5518568   0.17912847]\n",
      " [-0.5551494  -0.719139   -1.7393461   1.0084383  -0.8343097  -0.3490072\n",
      "  -1.1842831  -0.05278108  1.2000328   0.79528195]\n",
      " [-0.25930122  1.6491328  -0.576588    0.20397878 -1.3427229   0.7348453\n",
      "   0.93605685 -0.6909419  -1.0859869  -3.1433005 ]\n",
      " [-0.42067775  0.30126107  1.6660576   0.17846759 -0.58098996 -0.05399999\n",
      "  -0.8024532   0.08204538 -0.8270486  -0.6533913 ]\n",
      " [-0.6954217  -0.18104383  1.5689511   1.0846441   1.0638872   0.24641441\n",
      "   0.5751619   0.63819045  0.76238585  0.14609687]\n",
      " [ 0.9870894   1.0732305  -1.4681525  -0.81634253  0.33970132 -0.7715835\n",
      "  -0.13229224 -1.2610861  -0.14093159  0.6153246 ]], shape=(7, 10), dtype=float32) tf.Tensor(19.860487, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[ 1.016638   -0.13175517 -0.68637085 -1.5182903  -0.21121171 -0.30470392\n",
      "  -1.5144702  -0.20274104 -0.04936978  0.7065882 ]\n",
      " [-1.2623222   1.2453681   1.18454     1.3900931   0.13981585  1.8993542\n",
      "   0.9815698  -0.4767095   0.73440707  0.18623634]\n",
      " [ 1.8734637   0.8090439   0.58950967  0.04323136  0.9856188  -2.6696115\n",
      "   0.4090702   2.239537    1.9739711   0.76706034]\n",
      " [-0.          0.         -0.          0.         -0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.4888112  -0.39391103 -0.7453699   1.5803813   0.83021283  1.8892167\n",
      "   1.0820131  -0.06600883  1.371476    1.1268966 ]\n",
      " [ 0.41491526 -0.42497045  0.127392   -0.74920774 -0.68518096 -1.0810908\n",
      "   0.8759487   0.33674324 -0.31118068  0.98227257]\n",
      " [ 0.8621558  -0.10704158 -2.257687    0.53535295  0.92912716 -0.2683799\n",
      "   0.46124893 -0.57582146 -1.0668707  -0.86410743]\n",
      " [ 0.7054625   0.43681023 -0.4714849   0.7875362  -0.02482461  1.3705384\n",
      "   1.2356787   1.7327281   1.100737   -0.95458674]\n",
      " [ 0.60123277 -0.6207044   1.0912267  -0.96075225 -1.4253229  -1.9369231\n",
      "  -1.339159   -0.14088216  0.39934158 -2.701944  ]\n",
      " [ 0.16211794 -0.50593144  0.59609187  0.12006113  1.1661234  -0.4579844\n",
      "  -1.8476999  -1.4823775   0.3074556   0.5081123 ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[ 1.016638   -0.13175517 -0.68637085 -1.5182903  -0.21121171 -0.30470392\n",
      "  -1.5144702  -0.20274104 -0.04936978  0.7065882 ]\n",
      " [-1.2623222   1.2453681   1.18454     1.3900931   0.13981585  1.8993542\n",
      "   0.9815698  -0.4767095   0.73440707  0.18623634]\n",
      " [ 1.8734637   0.8090439   0.58950967  0.04323136  0.9856188  -2.6696115\n",
      "   0.4090702   2.239537    1.9739711   0.76706034]], shape=(3, 10), dtype=float32) tf.Tensor(10.773592, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[ 0.4888112  -0.39391103 -0.7453699   1.5803813   0.83021283  1.8892167\n",
      "   1.0820131  -0.06600883  1.371476    1.1268966 ]\n",
      " [ 0.41491526 -0.42497045  0.127392   -0.74920774 -0.68518096 -1.0810908\n",
      "   0.8759487   0.33674324 -0.31118068  0.98227257]\n",
      " [ 0.8621558  -0.10704158 -2.257687    0.53535295  0.92912716 -0.2683799\n",
      "   0.46124893 -0.57582146 -1.0668707  -0.86410743]\n",
      " [ 0.7054625   0.43681023 -0.4714849   0.7875362  -0.02482461  1.3705384\n",
      "   1.2356787   1.7327281   1.100737   -0.95458674]\n",
      " [ 0.60123277 -0.6207044   1.0912267  -0.96075225 -1.4253229  -1.9369231\n",
      "  -1.339159   -0.14088216  0.39934158 -2.701944  ]\n",
      " [ 0.16211794 -0.50593144  0.59609187  0.12006113  1.1661234  -0.4579844\n",
      "  -1.8476999  -1.4823775   0.3074556   0.5081123 ]], shape=(6, 10), dtype=float32) tf.Tensor(18.941248, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[-0.6032806   0.81516737 -0.05196144 -1.0714022  -0.53691     0.01255873\n",
      "  -0.07945862  1.1746117   1.103827    0.11511571]\n",
      " [ 1.5478638  -0.5989718   2.3766134   0.47850117 -1.2079166  -0.14901721\n",
      "  -1.3157192  -1.241815   -0.68383795 -0.19305664]\n",
      " [-0.33897504  0.2824182  -0.9944696  -1.0911914  -2.051984   -1.037755\n",
      "   0.46717092  1.5792747  -0.32143533  0.95321494]\n",
      " [ 0.3591942  -0.41335958 -1.1888149  -0.50212795  0.16653588  1.5942708\n",
      "  -1.9327692  -0.6550638   2.0528877  -2.0754762 ]\n",
      " [-0.         -0.          0.          0.         -0.          0.\n",
      "   0.          0.         -0.         -0.        ]\n",
      " [ 0.9585153   1.6278701   0.28519973 -0.50157946 -1.9865756  -0.3533516\n",
      "  -3.0859237   0.02768379 -2.175282   -1.4734524 ]\n",
      " [ 1.392334    0.668807   -0.28450075 -0.41068563 -0.28181714 -1.4833258\n",
      "   0.0689427   1.0913135  -0.05641784  0.9435319 ]\n",
      " [-0.8614538   0.19329634 -0.726686    0.50216913 -0.24691477  1.5821543\n",
      "   0.33160865 -0.42287147  1.1155492   1.5056494 ]\n",
      " [-1.0847282  -0.180551   -0.8367868   0.23357339 -1.4823238  -0.43584982\n",
      "   0.36750197  0.09357096  0.47040716  0.6604371 ]\n",
      " [ 0.6052748  -0.1062627   0.8155763   0.48723724  2.325986   -0.9237225\n",
      "   1.1738946  -0.26835272 -0.5240366   0.8683841 ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[-0.6032806   0.81516737 -0.05196144 -1.0714022  -0.53691     0.01255873\n",
      "  -0.07945862  1.1746117   1.103827    0.11511571]\n",
      " [ 1.5478638  -0.5989718   2.3766134   0.47850117 -1.2079166  -0.14901721\n",
      "  -1.3157192  -1.241815   -0.68383795 -0.19305664]\n",
      " [-0.33897504  0.2824182  -0.9944696  -1.0911914  -2.051984   -1.037755\n",
      "   0.46717092  1.5792747  -0.32143533  0.95321494]\n",
      " [ 0.3591942  -0.41335958 -1.1888149  -0.50212795  0.16653588  1.5942708\n",
      "  -1.9327692  -0.6550638   2.0528877  -2.0754762 ]], shape=(4, 10), dtype=float32) tf.Tensor(13.506351, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[ 0.9585153   1.6278701   0.28519973 -0.50157946 -1.9865756  -0.3533516\n",
      "  -3.0859237   0.02768379 -2.175282   -1.4734524 ]\n",
      " [ 1.392334    0.668807   -0.28450075 -0.41068563 -0.28181714 -1.4833258\n",
      "   0.0689427   1.0913135  -0.05641784  0.9435319 ]\n",
      " [-0.8614538   0.19329634 -0.726686    0.50216913 -0.24691477  1.5821543\n",
      "   0.33160865 -0.42287147  1.1155492   1.5056494 ]\n",
      " [-1.0847282  -0.180551   -0.8367868   0.23357339 -1.4823238  -0.43584982\n",
      "   0.36750197  0.09357096  0.47040716  0.6604371 ]\n",
      " [ 0.6052748  -0.1062627   0.8155763   0.48723724  2.325986   -0.9237225\n",
      "   1.1738946  -0.26835272 -0.5240366   0.8683841 ]], shape=(5, 10), dtype=float32) tf.Tensor(15.836882, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[ 0.4930996   0.52723193  0.56986    -1.5600607  -0.9685713   1.3941618\n",
      "  -0.5808408  -0.2894311   2.8884945  -0.57500726]\n",
      " [-0.23996179 -3.439973   -0.05968164 -1.7889766   0.28045028 -0.6204172\n",
      "  -0.3076865  -2.0425463  -0.3014851   1.0612376 ]\n",
      " [ 0.03855285  0.49341154  1.0783309  -1.9093883  -0.30717665  0.16649821\n",
      "  -0.8974289   0.32532415 -0.4509096  -0.4337515 ]\n",
      " [-1.3291335  -1.2623104  -2.589643    0.5509884  -0.49587932 -1.0434941\n",
      "  -0.8276698  -0.3120408  -1.0753986  -0.19768746]\n",
      " [-2.1898718   0.21221487 -1.2814286  -0.10883804  2.164472    0.24892132\n",
      "   0.9049906  -1.4248655  -1.2990512  -0.87752753]\n",
      " [ 0.          0.         -0.          0.          0.          0.\n",
      "  -0.          0.         -0.         -0.        ]\n",
      " [-0.0683982  -2.200945    1.5087451   0.09891412  1.556877    1.1442122\n",
      "  -0.45614854 -0.17620137 -0.45165917 -0.10019175]\n",
      " [-1.5502944  -0.6043425  -1.3683627   0.4646411  -0.34899205  2.7857592\n",
      "  -0.29338172 -0.55416995 -1.4880341   0.92520064]\n",
      " [-0.49739227 -1.4475288  -0.08747778 -0.07735398 -0.36450946 -0.38280922\n",
      "  -1.7485038   1.6696175   0.27428138 -0.97254694]\n",
      " [ 0.8008774  -0.30934125 -1.6622341  -1.9825943  -1.1061618  -0.86113983\n",
      "  -0.42502314  1.515952   -2.4832454  -0.3365136 ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[ 0.4930996   0.52723193  0.56986    -1.5600607  -0.9685713   1.3941618\n",
      "  -0.5808408  -0.2894311   2.8884945  -0.57500726]\n",
      " [-0.23996179 -3.439973   -0.05968164 -1.7889766   0.28045028 -0.6204172\n",
      "  -0.3076865  -2.0425463  -0.3014851   1.0612376 ]\n",
      " [ 0.03855285  0.49341154  1.0783309  -1.9093883  -0.30717665  0.16649821\n",
      "  -0.8974289   0.32532415 -0.4509096  -0.4337515 ]\n",
      " [-1.3291335  -1.2623104  -2.589643    0.5509884  -0.49587932 -1.0434941\n",
      "  -0.8276698  -0.3120408  -1.0753986  -0.19768746]\n",
      " [-2.1898718   0.21221487 -1.2814286  -0.10883804  2.164472    0.24892132\n",
      "   0.9049906  -1.4248655  -1.2990512  -0.87752753]], shape=(5, 10), dtype=float32) tf.Tensor(18.805363, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[-0.0683982  -2.200945    1.5087451   0.09891412  1.556877    1.1442122\n",
      "  -0.45614854 -0.17620137 -0.45165917 -0.10019175]\n",
      " [-1.5502944  -0.6043425  -1.3683627   0.4646411  -0.34899205  2.7857592\n",
      "  -0.29338172 -0.55416995 -1.4880341   0.92520064]\n",
      " [-0.49739227 -1.4475288  -0.08747778 -0.07735398 -0.36450946 -0.38280922\n",
      "  -1.7485038   1.6696175   0.27428138 -0.97254694]\n",
      " [ 0.8008774  -0.30934125 -1.6622341  -1.9825943  -1.1061618  -0.86113983\n",
      "  -0.42502314  1.515952   -2.4832454  -0.3365136 ]], shape=(4, 10), dtype=float32) tf.Tensor(14.733238, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[ 1.0537684  -0.388665    1.2278901   1.7634361   0.66931754  0.1787896\n",
      "   0.7128974   0.10226361 -0.92899644  1.0533009 ]\n",
      " [-1.5519214  -0.54475105 -0.52353436 -1.0810283  -1.4899653  -0.15394346\n",
      "  -1.6812122   0.2573755   0.79526913  0.05318882]\n",
      " [ 0.11400235 -0.5129767   1.260761    0.38548878 -0.45037046  0.05037273\n",
      "  -1.0843732  -0.740246    1.1194276   0.6299625 ]\n",
      " [ 0.841611   -0.63636917 -1.0706648   0.13281055 -1.6678028   0.507963\n",
      "  -0.41796932  0.80697536 -0.9693782   3.1640973 ]\n",
      " [-0.5588269  -0.35278943 -0.9711603  -0.5127585   0.12947716 -0.7184464\n",
      "   0.15552978 -0.3448308   0.9143687  -0.46880546]\n",
      " [ 0.96013737  0.6614733   0.94324803  0.47633478  0.89783734  0.51467204\n",
      "   0.03608324  0.7823477  -0.5738534  -0.01530664]\n",
      " [ 0.          0.          0.          0.         -0.          0.\n",
      "   0.          0.         -0.         -0.        ]\n",
      " [-1.0841153   0.9924611  -0.08884043  0.1536386  -0.29312173  0.824401\n",
      "  -0.50365764 -1.6462902   1.6200348   0.7464862 ]\n",
      " [ 1.3837806  -3.0199256   0.90432185  1.4783455  -1.5600787  -0.7612315\n",
      "   0.18431424  0.50822335  1.6800764  -0.99329096]\n",
      " [ 1.2255151   0.54347515  0.20169568  2.644742   -0.5350003   1.5233256\n",
      "  -0.041557    0.8235473  -1.3140223   0.09930754]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[ 1.0537684  -0.388665    1.2278901   1.7634361   0.66931754  0.1787896\n",
      "   0.7128974   0.10226361 -0.92899644  1.0533009 ]\n",
      " [-1.5519214  -0.54475105 -0.52353436 -1.0810283  -1.4899653  -0.15394346\n",
      "  -1.6812122   0.2573755   0.79526913  0.05318882]\n",
      " [ 0.11400235 -0.5129767   1.260761    0.38548878 -0.45037046  0.05037273\n",
      "  -1.0843732  -0.740246    1.1194276   0.6299625 ]\n",
      " [ 0.841611   -0.63636917 -1.0706648   0.13281055 -1.6678028   0.507963\n",
      "  -0.41796932  0.80697536 -0.9693782   3.1640973 ]\n",
      " [-0.5588269  -0.35278943 -0.9711603  -0.5127585   0.12947716 -0.7184464\n",
      "   0.15552978 -0.3448308   0.9143687  -0.46880546]\n",
      " [ 0.96013737  0.6614733   0.94324803  0.47633478  0.89783734  0.51467204\n",
      "   0.03608324  0.7823477  -0.5738534  -0.01530664]], shape=(6, 10), dtype=float32) tf.Tensor(16.579948, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[-1.0841153   0.9924611  -0.08884043  0.1536386  -0.29312173  0.824401\n",
      "  -0.50365764 -1.6462902   1.6200348   0.7464862 ]\n",
      " [ 1.3837806  -3.0199256   0.90432185  1.4783455  -1.5600787  -0.7612315\n",
      "   0.18431424  0.50822335  1.6800764  -0.99329096]\n",
      " [ 1.2255151   0.54347515  0.20169568  2.644742   -0.5350003   1.5233256\n",
      "  -0.041557    0.8235473  -1.3140223   0.09930754]], shape=(3, 10), dtype=float32) tf.Tensor(11.338699, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[ 0.23489659  0.08814491  0.4566898  -0.8002224  -0.2927384  -0.8216048\n",
      "  -1.0349208  -0.12415914 -0.46385142 -1.1263835 ]\n",
      " [ 0.88406116  0.92755353 -1.519214   -0.3002014  -1.6600258   0.97979254\n",
      "   0.77979046  0.9601667   0.27251664  1.5299003 ]\n",
      " [ 0.5069321  -0.7200986   2.0680583   0.43768832 -0.03520582  2.202395\n",
      "  -0.6043839  -0.80732316  1.507062    1.0162528 ]\n",
      " [-0.33132803 -0.668246    1.3557744   0.32276392  0.6280996  -2.3026717\n",
      "  -0.5700397   0.81367046  0.4237113   0.26088974]\n",
      " [ 1.7511106  -0.31336698  0.17374553  0.937438   -0.51905847 -0.8114174\n",
      "   1.8382385   0.12610345  0.98787844  0.6065079 ]\n",
      " [ 1.6985102   0.20425344  1.0164622   0.18248157 -0.43473366 -0.528549\n",
      "   1.5408294  -0.00842726 -0.29007602  0.53313226]\n",
      " [ 0.91493756 -1.1010151  -0.26953316  0.10757379  0.43875247 -0.83193827\n",
      "   0.5156022   0.5739097  -1.6474429   0.6801564 ]\n",
      " [-0.         -0.          0.         -0.         -0.          0.\n",
      "  -0.          0.         -0.          0.        ]\n",
      " [ 0.4933283   1.4082024   2.0417874  -0.76465064 -0.6370926  -0.38393247\n",
      "  -1.0464635   0.98719156 -0.2083561  -0.17755133]\n",
      " [-1.1784755  -0.10000996 -0.5207226  -0.553758   -0.30407578 -0.1245962\n",
      "   0.51607573  1.0261601   1.029366    0.8968233 ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[ 0.23489659  0.08814491  0.4566898  -0.8002224  -0.2927384  -0.8216048\n",
      "  -1.0349208  -0.12415914 -0.46385142 -1.1263835 ]\n",
      " [ 0.88406116  0.92755353 -1.519214   -0.3002014  -1.6600258   0.97979254\n",
      "   0.77979046  0.9601667   0.27251664  1.5299003 ]\n",
      " [ 0.5069321  -0.7200986   2.0680583   0.43768832 -0.03520582  2.202395\n",
      "  -0.6043839  -0.80732316  1.507062    1.0162528 ]\n",
      " [-0.33132803 -0.668246    1.3557744   0.32276392  0.6280996  -2.3026717\n",
      "  -0.5700397   0.81367046  0.4237113   0.26088974]\n",
      " [ 1.7511106  -0.31336698  0.17374553  0.937438   -0.51905847 -0.8114174\n",
      "   1.8382385   0.12610345  0.98787844  0.6065079 ]\n",
      " [ 1.6985102   0.20425344  1.0164622   0.18248157 -0.43473366 -0.528549\n",
      "   1.5408294  -0.00842726 -0.29007602  0.53313226]\n",
      " [ 0.91493756 -1.1010151  -0.26953316  0.10757379  0.43875247 -0.83193827\n",
      "   0.5156022   0.5739097  -1.6474429   0.6801564 ]], shape=(7, 10), dtype=float32) tf.Tensor(20.758991, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[ 0.4933283   1.4082024   2.0417874  -0.76465064 -0.6370926  -0.38393247\n",
      "  -1.0464635   0.98719156 -0.2083561  -0.17755133]\n",
      " [-1.1784755  -0.10000996 -0.5207226  -0.553758   -0.30407578 -0.1245962\n",
      "   0.51607573  1.0261601   1.029366    0.8968233 ]], shape=(2, 10), dtype=float32) tf.Tensor(5.4060974, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[-0.04146417  0.3502035   2.1723714   0.79205924 -0.38545012  0.5272389\n",
      "   0.3715587   1.5882109  -0.68514436  0.20969135]\n",
      " [ 0.39970413  0.6372002  -1.208519   -0.3232664   0.4470265  -0.5457411\n",
      "  -1.0523704  -0.8957541   1.7230988  -0.21568361]\n",
      " [-1.5369229  -0.23732835 -0.2959499  -0.7675964   0.9800632   0.53516775\n",
      "   0.64773047  1.2628099   0.9142398  -0.22079599]\n",
      " [-0.40892816  1.091431    0.889288    1.1119     -1.0752167  -1.3505402\n",
      "  -0.6862445  -0.14300844 -0.5152055   0.33006918]\n",
      " [ 0.7371987   1.7518071   1.2551402  -0.17470723  0.5739727  -0.03727936\n",
      "   0.10545092 -1.0504668   0.81271845  2.0724475 ]\n",
      " [-0.522518   -0.577367   -0.8098295   1.2451947   1.7442342   0.7359688\n",
      "  -1.896656    0.26796085 -2.0931854   1.1312386 ]\n",
      " [ 0.18809709  0.42257988 -0.01204645  0.20882407  2.0081818  -0.99897707\n",
      "  -0.84493065  0.17459281 -0.1305603   2.15498   ]\n",
      " [-0.8572524  -1.357037    1.5810993   0.62816775  0.30552167  0.44220778\n",
      "   1.8716562   0.22632657  1.0072764   0.65203285]\n",
      " [ 0.          0.          0.         -0.          0.         -0.\n",
      "   0.          0.         -0.          0.        ]\n",
      " [-0.5122473   0.13551885  0.786499    0.2516837   0.51950055 -0.15671085\n",
      "   1.1168562  -0.93122935 -0.15690787  0.08028421]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[-0.04146417  0.3502035   2.1723714   0.79205924 -0.38545012  0.5272389\n",
      "   0.3715587   1.5882109  -0.68514436  0.20969135]\n",
      " [ 0.39970413  0.6372002  -1.208519   -0.3232664   0.4470265  -0.5457411\n",
      "  -1.0523704  -0.8957541   1.7230988  -0.21568361]\n",
      " [-1.5369229  -0.23732835 -0.2959499  -0.7675964   0.9800632   0.53516775\n",
      "   0.64773047  1.2628099   0.9142398  -0.22079599]\n",
      " [-0.40892816  1.091431    0.889288    1.1119     -1.0752167  -1.3505402\n",
      "  -0.6862445  -0.14300844 -0.5152055   0.33006918]\n",
      " [ 0.7371987   1.7518071   1.2551402  -0.17470723  0.5739727  -0.03727936\n",
      "   0.10545092 -1.0504668   0.81271845  2.0724475 ]\n",
      " [-0.522518   -0.577367   -0.8098295   1.2451947   1.7442342   0.7359688\n",
      "  -1.896656    0.26796085 -2.0931854   1.1312386 ]\n",
      " [ 0.18809709  0.42257988 -0.01204645  0.20882407  2.0081818  -0.99897707\n",
      "  -0.84493065  0.17459281 -0.1305603   2.15498   ]\n",
      " [-0.8572524  -1.357037    1.5810993   0.62816775  0.30552167  0.44220778\n",
      "   1.8716562   0.22632657  1.0072764   0.65203285]], shape=(8, 10), dtype=float32) tf.Tensor(25.064209, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor(\n",
      "[[-0.5122473   0.13551885  0.786499    0.2516837   0.51950055 -0.15671085\n",
      "   1.1168562  -0.93122935 -0.15690787  0.08028421]], shape=(1, 10), dtype=float32) tf.Tensor(1.8446541, shape=(), dtype=float32)\n",
      "weigths tf.Tensor(\n",
      "[[-0.66659075 -0.85439175 -0.87608486 -0.8779217  -0.3560286   1.3605988\n",
      "   1.5575566  -0.29974774  2.0699253   0.22005521]\n",
      " [-0.09672973 -1.0293269   1.5420401  -1.1107074  -0.94784707 -1.226201\n",
      "   1.0951691   0.61087793  0.91164297  0.5090822 ]\n",
      " [-0.13835244  0.9909423  -1.5099256   0.0991232   0.7205701   0.4639761\n",
      "  -1.0074928  -2.0592034  -1.8210748   2.0819535 ]\n",
      " [ 0.08565301 -1.4858135  -2.0059865  -0.17614102 -0.29204577  0.8748151\n",
      "  -0.37564746  0.65407425  0.9288321  -1.204167  ]\n",
      " [ 0.4893988  -0.53270704 -0.71111375  0.3483111  -0.15402664  0.54348195\n",
      "   0.3541368  -1.1432884  -0.21900447 -0.04229448]\n",
      " [-1.4143298   0.6110132   1.073343    1.0690602   1.7435234   0.29389122\n",
      "   0.92905676 -0.53754073  0.05003964  0.23150764]\n",
      " [-1.5101217   0.24787569 -0.8726815   1.6097319   0.7600285   2.7344587\n",
      "   1.1231656  -1.1063706  -1.4966383   0.22978465]\n",
      " [-0.97418284 -0.4693508  -0.29017377 -0.5148949  -0.03402368  0.64632094\n",
      "  -0.56385124  1.4923033  -0.30602342  0.28944236]\n",
      " [-0.5805865   0.21033007 -0.89759964  1.646175    0.8910944   1.4808441\n",
      "   0.9540614   0.78101623  1.2956996   0.3984755 ]\n",
      " [ 0.          0.          0.          0.         -0.         -0.\n",
      "   0.         -0.          0.          0.        ]], shape=(10, 10), dtype=float32)\n",
      "w_1 tf.Tensor(\n",
      "[[-0.66659075 -0.85439175 -0.87608486 -0.8779217  -0.3560286   1.3605988\n",
      "   1.5575566  -0.29974774  2.0699253   0.22005521]\n",
      " [-0.09672973 -1.0293269   1.5420401  -1.1107074  -0.94784707 -1.226201\n",
      "   1.0951691   0.61087793  0.91164297  0.5090822 ]\n",
      " [-0.13835244  0.9909423  -1.5099256   0.0991232   0.7205701   0.4639761\n",
      "  -1.0074928  -2.0592034  -1.8210748   2.0819535 ]\n",
      " [ 0.08565301 -1.4858135  -2.0059865  -0.17614102 -0.29204577  0.8748151\n",
      "  -0.37564746  0.65407425  0.9288321  -1.204167  ]\n",
      " [ 0.4893988  -0.53270704 -0.71111375  0.3483111  -0.15402664  0.54348195\n",
      "   0.3541368  -1.1432884  -0.21900447 -0.04229448]\n",
      " [-1.4143298   0.6110132   1.073343    1.0690602   1.7435234   0.29389122\n",
      "   0.92905676 -0.53754073  0.05003964  0.23150764]\n",
      " [-1.5101217   0.24787569 -0.8726815   1.6097319   0.7600285   2.7344587\n",
      "   1.1231656  -1.1063706  -1.4966383   0.22978465]\n",
      " [-0.97418284 -0.4693508  -0.29017377 -0.5148949  -0.03402368  0.64632094\n",
      "  -0.56385124  1.4923033  -0.30602342  0.28944236]\n",
      " [-0.5805865   0.21033007 -0.89759964  1.646175    0.8910944   1.4808441\n",
      "   0.9540614   0.78101623  1.2956996   0.3984755 ]], shape=(9, 10), dtype=float32) tf.Tensor(28.178024, shape=(), dtype=float32)\n",
      "w_2 tf.Tensor([], shape=(0, 10), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## V_W\n",
    "L1_loss = 0.0\n",
    "for i in range(num_inputs):\n",
    "    print('weigths', weights['w_h0_'+str(i)])\n",
    "    w_1 = tf.slice(weights['w_h0_'+str(i)],[0,0],[i,-1])\n",
    "    print('w_1',w_1,tf.reduce_sum(tf.norm(w_1,axis=1)))\n",
    "    w_2 = tf.slice(weights['w_h0_'+str(i)],[i+1,0],[-1,-1])\n",
    "    print('w_2',w_2,tf.reduce_sum(tf.norm(w_2,axis=1)))\n",
    "    L1_loss += tf.reduce_sum(tf.norm(w_1,axis=1))+tf.reduce_sum(tf.norm(w_2,axis=1))\n",
    "#     print('L1_loss',L1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5000, 10), dtype=float32, numpy=\n",
       "array([[ 30.263233  , -14.155115  ,  -8.639004  , ..., -30.443684  ,\n",
       "          9.576943  ,   7.6275373 ],\n",
       "       [ 23.302568  ,  -0.694162  , -66.01288   , ..., -13.165191  ,\n",
       "          0.19194162,   0.6470868 ],\n",
       "       [ 28.847435  , -11.004281  , -59.29043   , ...,  -2.2444994 ,\n",
       "         -1.495836  ,   5.2679815 ],\n",
       "       ...,\n",
       "       [ 25.28162   ,  -6.9379907 , -17.31309   , ..., -13.811258  ,\n",
       "          7.228603  ,   3.171753  ],\n",
       "       [ 17.581148  , -15.1001835 ,  -3.6546338 , ..., -10.713383  ,\n",
       "          0.29217696,   1.2802916 ],\n",
       "       [ 19.721687  ,  14.499953  , -73.23136   , ...,  12.951685  ,\n",
       "          2.7972045 ,   2.2777574 ]], dtype=float32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample \n",
    "import random\n",
    "# Residuals\n",
    "R = X - Out \n",
    "\n",
    "num_nodes = np.shape(X_DAG)[1]\n",
    "num_inputs= X_DAG.shape[1]\n",
    "one_hot_sample = [0]*num_inputs\n",
    "subset_ = sample(range(num_inputs),num_nodes) \n",
    "for j in subset_:\n",
    "    one_hot_sample[j] = 1\n",
    "\n",
    "# Divide the residual into untrain and train subset\n",
    "_, subset_R = tf.dynamic_partition(tf.transpose(R), partitions=one_hot_sample, num_partitions=2)\n",
    "subset_R = tf.transpose(subset_R)\n",
    "\n",
    "subset_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5000, 1), dtype=float32, numpy=\n",
       "array([[-31.747768],\n",
       "       [-21.231436],\n",
       "       [-29.213648],\n",
       "       ...,\n",
       "       [-25.990349],\n",
       "       [-18.396084],\n",
       "       [-18.480753]], dtype=float32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Combine all the loss\n",
    "mse_loss_subset = tf.cast(num_inputs, tf.float32)/ tf.cast(tf.reduce_sum(one_hot_sample), tf.float32)* tf.reduce_sum(tf.square(subset_R))\n",
    "regularization_loss_subset =  mse_loss_subset +  reg_beta * L1_loss +  0.5 * h * h + h\n",
    "\n",
    "#Add in supervised loss\n",
    "supervised_loss = tf.reduce_mean(tf.reduce_sum(tf.square(out_layer['nn_0'] - y),axis=1),axis=0)\n",
    "# regularization_loss = 0\n",
    "\n",
    "regularization_loss_subset +=  supervised_loss\n",
    "\n",
    "regularization_loss_subset = tf.Variable(initial_value = regularization_loss_subset, shape=(), dtype=tf.dtypes.float32)\n",
    "\n",
    "\n",
    "out_layer['nn_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`tape` is required when a `Tensor` loss is passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-2a688f5b1ebe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloss_op_dag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularization_loss_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss_op_supervised\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msupervised_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mregularization_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnet\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \"\"\"\n\u001b[0;32m    496\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m--> 497\u001b[1;33m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[0;32m    498\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnet\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# TODO(josh11b): Test that we handle weight decay in a reasonable way.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`tape` is required when a `Tensor` loss is passed.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[0mtape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `tape` is required when a `Tensor` loss is passed."
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer_subset = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss_op_dag = optimizer_subset.minimize(var_list=None, loss=regularization_loss_subset)\n",
    "\n",
    "# loss_op_supervised = optimizer_subset.minimize(var_list=supervised_loss + regularization_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-2e1fb10203c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss_op_dag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregularization_loss_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from random import sample \n",
    "rho_i = np.array([[1.0]])\n",
    "alpha_i = np.array([[1.0]])\n",
    "\n",
    "count = 0\n",
    "best = 1e9\n",
    "best_value = 1e9\n",
    "for step in range(1, max_steps):\n",
    "    h_value, loss = sess.run([h, supervised_loss], feed_dict={X: X, y: y, keep_prob : 1, rho:rho_i, alpha:alpha_i, is_train : True, noise:0})\n",
    "    print(\"Step \" + str(step) + \", Loss= \" + \"{:.4f}\".format(loss),\" h_value:\", h_value) \n",
    "\n",
    "\n",
    "    for step1 in range(1, (X.shape[0] // batch_size) + 1):\n",
    "\n",
    "\n",
    "        idxs = random.sample(range(X.shape[0]), batch_size)\n",
    "        batch_x = X[idxs]\n",
    "        batch_y = np.expand_dims(batch_x[:,0], -1)\n",
    "        one_hot_sample = [0]*num_inputs\n",
    "        subset_ = sample(range(num_inputs),num_nodes) \n",
    "        for j in subset_:\n",
    "            one_hot_sample[j] = 1\n",
    "        sess.run(loss_op_dag, feed_dict={X: batch_x, y: batch_y, sample:one_hot_sample,\n",
    "                                                      keep_prob : 1, rho:rho_i, alpha:alpha_i, Lambda : reg_lambda, is_train : True, noise : 0})\n",
    "\n",
    "    val_loss = val_loss(X_val, y_val)\n",
    "    if val_loss < best_value:\n",
    "        best_value = val_loss\n",
    "    h_value, loss = sess.run([h, supervised_loss], feed_dict={X: X, y: y, keep_prob : 1, rho:rho_i, alpha:alpha_i, is_train : True, noise:0})\n",
    "    if step >= saves:\n",
    "        try:\n",
    "            if val_loss < best:\n",
    "                best = val_loss \n",
    "                saver.save(sess, tmp)\n",
    "                print(\"Saving model\")\n",
    "                count = 0\n",
    "            else:\n",
    "                count += 1\n",
    "        except:\n",
    "            print(\"Error caught in calculation\")\n",
    "\n",
    "    if count > patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "saver.restore(sess, tmp)\n",
    "W_est = sess.run(W, feed_dict={X: X, y: y, keep_prob : 1, rho:rho_i, alpha:alpha_i, is_train : True, noise:0})\n",
    "W_est[np.abs(W_est) < w_threshold] = 0\n",
    "\n",
    "\n",
    "def val_loss(self, X, y):\n",
    "    if len(y.shape) < 2:\n",
    "        y = np.expand_dims(y, -1)\n",
    "    from random import sample \n",
    "    one_hot_sample = [0]*num_inputs\n",
    "\n",
    "    # use all values for validation\n",
    "    subset_ = sample(range(num_inputs),num_inputs) \n",
    "    for j in subset_:\n",
    "        one_hot_sample[j] = 1\n",
    "\n",
    "    return sess.run(supervised_loss, feed_dict={X: X, y: y, sample:one_hot_sample, keep_prob : 1, rho:np.array([[1.0]]), \n",
    "                                                          alpha:np.array([[0.0]]), Lambda : reg_lambda, is_train : False, noise:0})\n",
    "\n",
    "\n",
    "def pred(self, X):\n",
    "    return sess.run(out_layer['nn_0'], feed_dict={X: X, keep_prob:1, is_train : False, noise:0})\n",
    "\n",
    "def get_weights(self, X, y):\n",
    "    return sess.run(W, feed_dict={X: X, y: y, keep_prob : 1, rho:np.array([[1.0]]), alpha:np.array([[0.0]]), is_train : False, noise:0})\n",
    "\n",
    "def pred_W(self, X, y):\n",
    "    W_est = sess.run(W, feed_dict={X: X, y: y, keep_prob : 1, rho:np.array([[1.0]]), alpha:np.array([[0.0]]), is_train : False, noise:0})\n",
    "    return np.round_(W_est,decimals=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnet",
   "language": "python",
   "name": "gnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
